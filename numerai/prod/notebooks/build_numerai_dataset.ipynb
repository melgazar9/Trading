{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "# This notebook builds the stock market / numerai dataset"
=======
   "id": "prostate-framework",
   "metadata": {},
   "source": [
    "# This notebook builds the stock market / numerai dataset using dask"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "breeding-triumph",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "breeding-triumph"
   },
   "source": [
<<<<<<< HEAD
    "### Imports\n",
    "All other necessary imports are imported via python scripts"
=======
    "### Imports"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
=======
   "id": "amber-cabin",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "amber-cabin"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "#### Make cells wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
=======
   "id": "RU-UGOk2rA8w",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "RU-UGOk2rA8w"
   },
   "source": [
    "### Only run the below if on google colab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
<<<<<<< HEAD
=======
   "id": "5vQqHDb0qRLd",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vQqHDb0qRLd",
    "outputId": "6731e0c2-99ac-40b0-b86c-5ecf33dbb34f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
=======
   "id": "UreNrl9srNXa",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "UreNrl9srNXa"
   },
   "outputs": [],
   "source": [
    "# sys.path.append('/content/gdrive/trading/dev/scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
=======
   "id": "0l6obyRwr9qy",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "0l6obyRwr9qy"
   },
   "outputs": [],
   "source": [
    "# from gdrive.MyDrive.trading.dev.scripts.ML_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "fBnjdmz6rOHn",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "fBnjdmz6rOHn"
   },
   "source": [
    "### Only run if on local machine"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 2,
   "id": "continuous-chemical",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "continuous-chemical"
   },
   "outputs": [],
   "source": [
    "os.chdir('../..') # local"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 3,
   "id": "chief-death",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "chief-death"
   },
   "outputs": [],
   "source": [
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '16'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 4,
   "id": "through-contract",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 1.7 s, sys: 1.99 s, total: 3.7 s\n",
      "Wall time: 1.75 s\n"
=======
      "Wall time: 7.28 s\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dev.scripts.ML_utils import * # run if on local machine\n",
<<<<<<< HEAD
    "from dev.scripts.numerai_utils import *\n",
    "\n",
    "from dev.scripts.trading_utils import * # run if on local machine"
=======
    "from dev.scripts.numerai_utils import *"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "norwegian-insured",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "norwegian-insured"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "phantom-conclusion",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "source": [
    "#### Read in the numerai keys via config parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('numerai/numerai_keys.ini')\n",
    "\n",
    "OUTPUT_PATH = '/media/melgazar9/HDD_10TB/trading/data/yfinance/'"
=======
   "id": "dynamic-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerai/numerai_keys.ini']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('numerai/numerai_keys.ini')"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
   "id": "logical-stage",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "logical-stage"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 99 µs, sys: 98 µs, total: 197 µs\n",
      "Wall time: 203 µs\n"
=======
      "Wall time: 1.01 ms\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DOWNLOAD_NUMERAI_COMPETITION_DATA = False\n",
<<<<<<< HEAD
    "LOAD_NUMERAI_COMPETITION_DATA = False\n",
    "\n",
    "DF_NUMERAI_COMP_TRAIN_PATH = '/media/melgazar9/HDD_10TB/trading/data/numerai_dataset_255/numerai_training_data.csv' # local\n",
=======
    "USE_NUMERAI_COMPETITION_DATA = False\n",
    "\n",
    "DF_NUMERAI_COMP_TRAIN_PATH = 'C:/Users/Matt/trading/numerai/data/numerai_dataset_255/numerai_training_data.csv' # local\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "\n",
    "napi = numerapi.SignalsAPI(config['KEYS']['NUMERAI_PUBLIC_KEY'], config['KEYS']['NUMERAI_SECRET_KEY'])\n",
    "\n",
    "# download data\n",
    "if DOWNLOAD_NUMERAI_COMPETITION_DATA:\n",
    "\n",
    "    # napi = numerapi.NumerAPI(NUMERAI_PUBLIC_KEY, NUMERAI_SECRET_KEY)\n",
    "    napi.download_current_dataset(unzip=True)\n",
    "\n",
<<<<<<< HEAD
    "if LOAD_NUMERAI_COMPETITION_DATA:\n",
    "    df_numerai_comp = dd.read_csv(DF_NUMERAI_COMP_TRAIN_PATH).compute()\n",
    "    display(df_numerai_comp.tail(2))"
=======
    "    if USE_NUMERAI_COMPETITION_DATA:\n",
    "        df_numerai_comp = dd.read_csv(DF_NUMERAI_COMP_TRAIN_PATH).compute()\n",
    "        df_numerai_comp.tail(2)"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "ZC3OYstYxhEB",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "ZC3OYstYxhEB"
   },
   "source": [
<<<<<<< HEAD
    "## Load eligible tickers"
=======
    "## Load in eligible tickers"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 13,
   "id": "Jw1AlEWtxT6w",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw1AlEWtxT6w",
    "outputId": "4ba6e5c5-67d3-4db5-d090-e4baf38373ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Number of eligible tickers: 5430\n",
      "Number of eligible tickers in map: 5430\n"
=======
      "Number of eligible tickers: 5431\n",
      "Number of eligible tickers in map: 5431\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>yahoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>5428</th>\n",
=======
       "      <th>5429</th>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>ZYXI</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>5429</th>\n",
=======
       "      <th>5430</th>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>ZZZ.</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker bloomberg_ticker   yahoo\n",
<<<<<<< HEAD
       "5428   ZYXI          ZYXI US    ZYXI\n",
       "5429   ZZZ.           ZZZ CN  ZZZ.TO"
      ]
     },
     "execution_count": 11,
=======
       "5429   ZYXI          ZYXI US    ZYXI\n",
       "5430   ZZZ.           ZZZ CN  ZZZ.TO"
      ]
     },
     "execution_count": 13,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible_tickers = pd.Series(napi.ticker_universe(), name='ticker')\n",
    "print(f\"Number of eligible tickers: {len(eligible_tickers)}\")\n",
    "ticker_map = pd.read_csv('https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv')\n",
    "ticker_map = ticker_map[ticker_map['bloomberg_ticker'].isin(eligible_tickers)]\n",
    "print(f\"Number of eligible tickers in map: {len(ticker_map)}\")\n",
    "ticker_map.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "liked-dialogue",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "source": [
    "#### Remove null tickers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 11,
   "id": "through-classroom",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "tickers before: (5430, 3)\n",
=======
      "tickers before: (5431, 3)\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
      "tickers after: (5380, 3)\n"
     ]
    }
   ],
   "source": [
    "valid_tickers = [i for i in ticker_map['yahoo']\n",
    "     if not pd.isnull(i)\n",
    "     and not str(i).lower()=='nan' \\\n",
    "     and not str(i).lower()=='null' \\\n",
<<<<<<< HEAD
    "     and not str(i).lower()==''\\\n",
=======
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "]\n",
    "\n",
    "print('tickers before:', ticker_map.shape) # before removing bad tickers\n",
    "ticker_map = ticker_map[ticker_map['yahoo'].isin(valid_tickers)]\n",
    "print('tickers after:', ticker_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Download or load in yahoo finance data in the expected numerai format using the yfinance library\n",
    "Yahoo Finance wrappers: https://github.com/ranaroussi/yfinance and https://pypi.org/project/yfinance/. <br>\n",
    "Downloading ~2 hours on a single-thread"
=======
   "id": "cultural-netscape",
   "metadata": {},
   "source": [
    "## Download yahoo finance data in the expected numerai format using the yfinance library\n",
    "Yahoo Finance wrappers: https://github.com/ranaroussi/yfinance and https://pypi.org/project/yfinance/. <br>\n",
    "This takes ~2 hours on a single-thread\n",
    "\n",
    "### Convert the yahoo df to a dask df\n",
    "- If we don't do this the computation will be very slow. There are ~20 million rows of daily data alone. <br>\n",
    "- Once I add in intraday data and create additional features, it is necessary to use a lazy computation such as dask or spark. <br>\n",
    "\n",
    "- Lastly, we'll merge in the numerai target variable and save the ddf as a parquet file"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 28,
   "id": "latter-confirmation",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 18.4 s, sys: 33.6 s, total: 52 s\n",
      "Wall time: 31.3 s\n"
=======
      "Wall time: 4.23 s\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_1h_15</th>\n",
       "      <th>volume_1h_16</th>\n",
       "      <th>volume_1h_17</th>\n",
       "      <th>volume_1h_18</th>\n",
       "      <th>volume_1h_19</th>\n",
       "      <th>volume_1h_20</th>\n",
       "      <th>volume_1h_21</th>\n",
       "      <th>volume_1h_22</th>\n",
       "      <th>volume_1h_23</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
=======
       "      <th>17616892</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZURN.SW</td>\n",
       "      <td>406.200012</td>\n",
       "      <td>406.200012</td>\n",
       "      <td>410.799988</td>\n",
       "      <td>405.899994</td>\n",
       "      <td>409.00</td>\n",
       "      <td>1.617723e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZURN SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616893</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>14.860000</td>\n",
       "      <td>15.38</td>\n",
       "      <td>2.858690e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100865.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>33090.0</td>\n",
       "      <td>19464.0</td>\n",
       "      <td>49338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616894</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>14.860000</td>\n",
       "      <td>15.38</td>\n",
       "      <td>2.858690e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100865.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>33090.0</td>\n",
       "      <td>19464.0</td>\n",
       "      <td>49338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <th>17616895</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616896</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
<<<<<<< HEAD
       "<p>2 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date yahoo_ticker  adj_close_1d   close_1d    high_1d  \\\n",
       "17616895 2021-04-06       ZZZ.TO     31.879999  31.879999  32.240002   \n",
       "17616896 2021-04-06       ZZZ.TO     31.879999  31.879999  32.240002   \n",
       "\n",
       "             low_1d  open_1d     volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "17616895  31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "17616896  31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "\n",
       "          ...  volume_1h_15  volume_1h_16  volume_1h_17  volume_1h_18  \\\n",
=======
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date yahoo_ticker  adj_close_1d    close_1d     high_1d  \\\n",
       "17616892 2021-04-06      ZURN.SW    406.200012  406.200012  410.799988   \n",
       "17616893 2021-04-06         ZYXI     15.290000   15.290000   15.420000   \n",
       "17616894 2021-04-06         ZYXI     15.290000   15.290000   15.420000   \n",
       "17616895 2021-04-06       ZZZ.TO     31.879999   31.879999   32.240002   \n",
       "17616896 2021-04-06       ZZZ.TO     31.879999   31.879999   32.240002   \n",
       "\n",
       "              low_1d  open_1d     volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "17616892  405.899994   409.00  1.617723e+12             NaN             NaN   \n",
       "17616893   14.860000    15.38  2.858690e+05             NaN             NaN   \n",
       "17616894   14.860000    15.38  2.858690e+05             NaN             NaN   \n",
       "17616895   31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "17616896   31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "\n",
       "          ...  volume_1h_15  volume_1h_16  volume_1h_17  volume_1h_18  \\\n",
       "17616892  ...       60604.0           NaN           NaN           NaN   \n",
       "17616893  ...      100865.0        8730.0       33090.0       19464.0   \n",
       "17616894  ...      100865.0        8730.0       33090.0       19464.0   \n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "17616895  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "17616896  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "\n",
       "          volume_1h_19  volume_1h_20  volume_1h_21  volume_1h_22  \\\n",
<<<<<<< HEAD
=======
       "17616892           NaN           NaN           NaN           NaN   \n",
       "17616893       49338.0           NaN           NaN           NaN   \n",
       "17616894       49338.0           NaN           NaN           NaN   \n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "17616895        6188.0           NaN           NaN           NaN   \n",
       "17616896        6188.0           NaN           NaN           NaN   \n",
       "\n",
       "          volume_1h_23  bloomberg_ticker  \n",
<<<<<<< HEAD
       "17616895           NaN            ZZZ CN  \n",
       "17616896           NaN            ZZZ CN  \n",
       "\n",
       "[2 rows x 153 columns]"
      ]
     },
     "execution_count": 13,
=======
       "17616892           NaN           ZURN SW  \n",
       "17616893           NaN           ZYXI US  \n",
       "17616894           NaN           ZYXI US  \n",
       "17616895           NaN            ZZZ CN  \n",
       "17616896           NaN            ZZZ CN  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 28,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DOWNLOAD_YAHOO_DATA = False\n",
    "if DOWNLOAD_YAHOO_DATA:\n",
<<<<<<< HEAD
    "    df_yahoo = dd.from_pandas(download_yfinance_data(list(ticker_map['yahoo']), start='2006-01-01')) # all valid yahoo tickers\n",
    "else:\n",
    "    DF_YAHOO_FILEPATH = '/media/melgazar9/HDD_10TB/trading/data/yfinance/df_yahoo_2021-04-07.pq'\n",
    "    NPARTITIONS=16\n",
    "    if DF_YAHOO_FILEPATH.lower().endswith('pq') or DF_YAHOO_FILEPATH.lower().endswith('parquet'):\n",
    "        df_yahoo = dd.read_parquet(DF_YAHOO_FILEPATH,\n",
    "                                    npartitions=NPARTITIONS).compute()\n",
    "    elif DF_YAHOO_FILEPATH.lower().endswith('feather'):\n",
    "        df_yahoo = dd.from_pandas(delayed(feather.read_dataframe)(DF_YAHOO_FILEPATH).compute(),\n",
    "                                   npartitions=NPARTITIONS).compute()\n",
    "\n",
    "df_yahoo.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17616897 entries, 0 to 17616896\n",
      "Columns: 153 entries, date to bloomberg_ticker\n",
      "dtypes: datetime64[ns](1), float64(150), object(2)\n",
      "memory usage: 20.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_yahoo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the yahoo tickers to bloomberg tickers in the ddf_yahoo\n",
    "Set to True if downloading data. The mapping should already be saved in the dumped parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_BLOOMBERG_TICKER_FROM_YAHOO = False\n",
    "if CREATE_BLOOMBERG_TICKER_FROM_YAHOO:\n",
    "    df_yahoo.loc[:, 'bloomberg_ticker'] = df_yahoo['yahoo_ticker'].map(dict(zip(ticker_map['yahoo'], ticker_map['bloomberg_ticker'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save df_yahoo to a feather or parquet file for faster loading"
=======
    "    ddf_yahoo = dd.from_pandas(download_yfinance_data(list(ticker_map['yahoo']), start='2006-01-01')) # all yahoo tickers\n",
    "else:\n",
    "    DF_YAHOO_FILEPATH = 'data/yfinance/df_yahoo_2021-04-07.pq'\n",
    "    NPARTITIONS=16\n",
    "    if DF_YAHOO_FILEPATH.lower().endswith('pq') or DF_YAHOO_FILEPATH.lower().endswith('parquet'):\n",
    "        ddf_yahoo = dd.read_parquet(DF_YAHOO_FILEPATH,\n",
    "                                    npartitions=NPARTITIONS)\n",
    "    elif DF_YAHOO_FILEPATH.lower().endswith('feather'):\n",
    "        ddf_yahoo = dd.from_pandas(delayed(feather.read_dataframe)('data/yfinance/df_yahoo_2021-04-06.feather').compute(),\n",
    "                                   npartitions=NPARTITIONS)\n",
    "\n",
    "ddf_yahoo.tail()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 23 µs, total: 36 µs\n",
      "Wall time: 42.9 µs\n"
=======
   "execution_count": 32,
   "id": "front-vermont",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 1321268416 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \"\"\"\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\threaded.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mpools\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     results = get_async(\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                         \u001b[0m_execute_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Re-execute locally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m                         \u001b[0mraise_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cache\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\core.py\u001b[0m in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# temporaries by their reference count and can execute certain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# operations in-place.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py\u001b[0m in \u001b[0;36mread_parquet_part\u001b[1;34m(fs, func, meta, part, columns, index, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         dfs = [\n\u001b[0m\u001b[0;32m    384\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtoolz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         dfs = [\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtoolz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         ]\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py\u001b[0m in \u001b[0;36mread_partition\u001b[1;34m(cls, fs, piece, columns, index, categories, partitions, filters, schema, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[0marrow_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrow_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arrow_table_to_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrow_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# For pyarrow.dataset api, need to convert partition columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py\u001b[0m in \u001b[0;36m_arrow_table_to_pandas\u001b[1;34m(cls, arrow_table, categories, **kwargs)\u001b[0m\n\u001b[0;32m   1578\u001b[0m         \u001b[0m_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"use_threads\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_metadata\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marrow_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36mtable_to_blockmanager\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[0m_check_data_column_metadata_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_column_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_table_to_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext_columns_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[1;31m# Convert an arrow table to Block from the internal pandas API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m     result = pa.lib.table_to_blocks(options, block_table, categories,\n\u001b[0m\u001b[0;32m   1132\u001b[0m                                     list(extension_columns.keys()))\n\u001b[0;32m   1133\u001b[0m     return [_reconstruct_block(item, columns, extension_columns)\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyarrow\\error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 1321268416 failed"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "SAVE_DF_YAHOO_TO_FEATHER = False\n",
    "SAVE_DF_YAHOO_TO_PARQUET = False\n",
    "\n",
    "DF_YAHOO_OUTPATH = 'data/yfinance/df_yahoo_' + str(datetime.datetime.today().date())\n",
    "if SAVE_DF_YAHOO_TO_FEATHER:\n",
    "    df_yahoo.reset_index().to_feather(DF_YAHOO_OUTPATH + '.feather')\n",
    "if SAVE_DF_YAHOO_TO_PARQUET:\n",
    "    df_yahoo.to_parquet(DF_YAHOO_OUTPATH + '.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the numerai targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 602 ms, total: 1.91 s\n",
      "Wall time: 16.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4299721</th>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299722</th>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-03-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bloomberg_ticker  friday_date   data_type  target       date\n",
       "4299721          ZYXI US     20210326  validation     0.5 2021-03-26\n",
       "4299722           ZZZ CN     20210326  validation     0.5 2021-03-26"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv' # old\n",
    "targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val_bbg.csv'\n",
    "\n",
    "targets = pd.read_csv(targets_address)\\\n",
    "            .assign(date = lambda df: pd.to_datetime(df['friday_date'], format='%Y%m%d'))\n",
    "targets.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.50    2151203\n",
       " 0.25     859478\n",
       " 0.75     859032\n",
       " 1.00     215071\n",
       " 0.00     214939\n",
       " Name: target, dtype: int64,\n",
       " 0.50    0.500312\n",
       " 0.25    0.199891\n",
       " 0.75    0.199788\n",
       " 1.00    0.050020\n",
       " 0.00    0.049989\n",
       " Name: target, dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['target'].value_counts(), targets['target'].value_counts(normalize=True)"
=======
    "\n",
    "df_tmp = ddf_yahoo.compute()\n",
    "\n",
    "print(df_tmp.shape)\n",
    "print(df_tmp.dropna().shape)\n",
    "print(df_tmp.dropna(axis=1).shape)\n",
    "print(df_tmp[[i for i in df_tmp.columns if i.endswith('d')]].dropna().shape)\n",
    "del df_tmp"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 36,
   "id": "solar-check",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(17616897, 153)\n",
      "(0, 153)\n",
      "(17616897, 3)\n",
      "(17551417, 6)\n",
      "CPU times: user 10.2 s, sys: 2.06 s, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
=======
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 153 entries, date to bloomberg_ticker\n",
      "dtypes: datetime64[ns](1), object(2), float64(150)"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "%%time\n",
    "print(df_yahoo.shape)\n",
    "print(df_yahoo.dropna().shape)\n",
    "print(df_yahoo.dropna(axis=1).shape)\n",
    "print(df_yahoo[[i for i in df_yahoo.columns if i.endswith('d')]].dropna().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First iteration (reduced dataset size)"
=======
    "ddf_yahoo.info()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "### Merge targets into ddf_yahoo\n",
    "- From an inner join on `['date', 'bloomberg_ticker']` we lose about 85% of rows. <br>\n",
    "- If we drop rows with NAs we have 0 rows left no matter what. <br>\n",
    "- The best bet seems to be an outer join without dropping NA rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "- By doing an inner join we lose about 85% of the rows"
=======
   "id": "capable-macro",
   "metadata": {},
   "source": [
    "### Map the yahoo tickers to bloomberg tickers in the ddf_yahoo\n",
    "Set to True if reading data - I already saved the bloomberg ticker in the dumped parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vanilla-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloomberg_yahoo_tickermap(df,\n",
    "                              ticker_map_dict = dict(zip(ticker_map['yahoo'],\\\n",
    "                                                         ticker_map['bloomberg_ticker']))):\n",
    "    \n",
    "    df.loc[:, 'bloomberg_ticker'] = df['yahoo_ticker'].map(ticker_map_dict)\n",
    "    return df"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.14 s, sys: 1.03 s, total: 6.17 s\n",
      "Wall time: 6.18 s\n"
     ]
    },
    {
=======
   "execution_count": 38,
   "id": "funded-regulation",
   "metadata": {},
   "outputs": [
    {
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>...</th>\n",
<<<<<<< HEAD
=======
       "      <th>volume_1h_15</th>\n",
       "      <th>volume_1h_16</th>\n",
       "      <th>volume_1h_17</th>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <th>volume_1h_18</th>\n",
       "      <th>volume_1h_19</th>\n",
       "      <th>volume_1h_20</th>\n",
       "      <th>volume_1h_21</th>\n",
       "      <th>volume_1h_22</th>\n",
       "      <th>volume_1h_23</th>\n",
       "      <th>bloomberg_ticker</th>\n",
<<<<<<< HEAD
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
=======
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>2633674</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZURN.SW</td>\n",
       "      <td>402.100006</td>\n",
       "      <td>402.100006</td>\n",
       "      <td>404.700012</td>\n",
       "      <td>400.899994</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>512509.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
=======
       "      <th>17616892</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZURN.SW</td>\n",
       "      <td>406.200012</td>\n",
       "      <td>406.200012</td>\n",
       "      <td>410.799988</td>\n",
       "      <td>405.899994</td>\n",
       "      <td>409.00</td>\n",
       "      <td>1.617723e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZURN SW</td>\n",
<<<<<<< HEAD
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633675</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>456200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65519.0</td>\n",
       "      <td>63185.0</td>\n",
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616893</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>14.860000</td>\n",
       "      <td>15.38</td>\n",
       "      <td>2.858690e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100865.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>33090.0</td>\n",
       "      <td>19464.0</td>\n",
       "      <td>49338.0</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
<<<<<<< HEAD
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633676</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>456200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65519.0</td>\n",
       "      <td>63185.0</td>\n",
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616894</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.290000</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>14.860000</td>\n",
       "      <td>15.38</td>\n",
       "      <td>2.858690e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100865.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>33090.0</td>\n",
       "      <td>19464.0</td>\n",
       "      <td>49338.0</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
<<<<<<< HEAD
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633677</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>5578.0</td>\n",
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616895</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
<<<<<<< HEAD
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633678</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>5578.0</td>\n",
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616896</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
<<<<<<< HEAD
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date yahoo_ticker  adj_close_1d    close_1d     high_1d  \\\n",
       "2633674 2021-03-26      ZURN.SW    402.100006  402.100006  404.700012   \n",
       "2633675 2021-03-26         ZYXI     14.880000   14.880000   15.500000   \n",
       "2633676 2021-03-26         ZYXI     14.880000   14.880000   15.500000   \n",
       "2633677 2021-03-26       ZZZ.TO     32.060001   32.060001   32.060001   \n",
       "2633678 2021-03-26       ZZZ.TO     32.060001   32.060001   32.060001   \n",
       "\n",
       "             low_1d     open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "2633674  400.899994  401.000000   512509.0             NaN             NaN   \n",
       "2633675   14.400000   15.500000   456200.0             NaN             NaN   \n",
       "2633676   14.400000   15.500000   456200.0             NaN             NaN   \n",
       "2633677   31.625000   31.709999    40900.0             NaN             NaN   \n",
       "2633678   31.625000   31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "         ...  volume_1h_18  volume_1h_19  volume_1h_20  volume_1h_21  \\\n",
       "2633674  ...           NaN           NaN           NaN           NaN   \n",
       "2633675  ...       65519.0       63185.0           NaN           NaN   \n",
       "2633676  ...       65519.0       63185.0           NaN           NaN   \n",
       "2633677  ...        5822.0        5578.0           NaN           NaN   \n",
       "2633678  ...        5822.0        5578.0           NaN           NaN   \n",
       "\n",
       "         volume_1h_22  volume_1h_23  bloomberg_ticker  friday_date  \\\n",
       "2633674           NaN           NaN           ZURN SW     20210326   \n",
       "2633675           NaN           NaN           ZYXI US     20210326   \n",
       "2633676           NaN           NaN           ZYXI US     20210326   \n",
       "2633677           NaN           NaN            ZZZ CN     20210326   \n",
       "2633678           NaN           NaN            ZZZ CN     20210326   \n",
       "\n",
       "          data_type  target  \n",
       "2633674  validation    0.25  \n",
       "2633675  validation    0.50  \n",
       "2633676  validation    0.50  \n",
       "2633677  validation    0.50  \n",
       "2633678  validation    0.50  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 20,
=======
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date yahoo_ticker  adj_close_1d    close_1d     high_1d  \\\n",
       "17616892 2021-04-06      ZURN.SW    406.200012  406.200012  410.799988   \n",
       "17616893 2021-04-06         ZYXI     15.290000   15.290000   15.420000   \n",
       "17616894 2021-04-06         ZYXI     15.290000   15.290000   15.420000   \n",
       "17616895 2021-04-06       ZZZ.TO     31.879999   31.879999   32.240002   \n",
       "17616896 2021-04-06       ZZZ.TO     31.879999   31.879999   32.240002   \n",
       "\n",
       "              low_1d  open_1d     volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "17616892  405.899994   409.00  1.617723e+12             NaN             NaN   \n",
       "17616893   14.860000    15.38  2.858690e+05             NaN             NaN   \n",
       "17616894   14.860000    15.38  2.858690e+05             NaN             NaN   \n",
       "17616895   31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "17616896   31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "\n",
       "          ...  volume_1h_15  volume_1h_16  volume_1h_17  volume_1h_18  \\\n",
       "17616892  ...       60604.0           NaN           NaN           NaN   \n",
       "17616893  ...      100865.0        8730.0       33090.0       19464.0   \n",
       "17616894  ...      100865.0        8730.0       33090.0       19464.0   \n",
       "17616895  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "17616896  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "\n",
       "          volume_1h_19  volume_1h_20  volume_1h_21  volume_1h_22  \\\n",
       "17616892           NaN           NaN           NaN           NaN   \n",
       "17616893       49338.0           NaN           NaN           NaN   \n",
       "17616894       49338.0           NaN           NaN           NaN   \n",
       "17616895        6188.0           NaN           NaN           NaN   \n",
       "17616896        6188.0           NaN           NaN           NaN   \n",
       "\n",
       "          volume_1h_23  bloomberg_ticker  \n",
       "17616892           NaN           ZURN SW  \n",
       "17616893           NaN           ZYXI US  \n",
       "17616894           NaN           ZYXI US  \n",
       "17616895           NaN            ZZZ CN  \n",
       "17616896           NaN            ZZZ CN  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 38,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "%%time\n",
    "# print('Before: ', df_yahoo.shape[0].compute(), df_yahoo.shape[1])\n",
    "df_yahoo = pd.merge(df_yahoo, targets, on=['date', 'bloomberg_ticker'], how='inner')\n",
    "\n",
    "# print('After: ', df_yahoo.shape[0].compute(), df_yahoo.shape[1])\n",
    "df_yahoo.tail()"
=======
    "SET_BLOOMBERG_TICKERS_AS_INDEX = False\n",
    "if SET_BLOOMBERG_TICKERS_AS_INDEX:\n",
    "    ddf_yahoo = ddf_yahoo.map_partitions(bloomberg_yahoo_tickermap)\n",
    "\n",
    "ddf_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-indianapolis",
   "metadata": {},
   "source": [
    "### Save df_yahoo to a feather file for faster loading"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 39,
   "id": "coral-priest",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 5.11 ms, sys: 0 ns, total: 5.11 ms\n",
      "Wall time: 4.58 ms\n"
=======
      "Wall time: 0 ns\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "df_yahoo.set_index('date', inplace=True)\n",
    "df_yahoo.sort_index(inplace=True)"
=======
    "SAVE_DF_YAHOO_TO_FEATHER = False\n",
    "SAVE_DF_YAHOO_TO_PARQUET = False\n",
    "\n",
    "DDF_YAHOO_OUTPATH = 'data/yfinance/df_yahoo_' + str(datetime.datetime.today().date())\n",
    "if SAVE_DF_YAHOO_TO_FEATHER:\n",
    "    ddf_yahoo.reset_index().to_feather(DDF_YAHOO_OUTPATH + '.feather')\n",
    "if SAVE_DF_YAHOO_TO_PARQUET:\n",
    "    dd.to_parquet(ddf_yahoo,\n",
    "                  path=DDF_YAHOO_OUTPATH + '.pq'#,\n",
    "#                   engine='fastparquet', # fails on windows\n",
    "#                   storage_options={'key':key, 'secret':secret} # used to store on server\n",
    "                 )"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "#### Drop rows where the daily prices are NA\n",
    "By dropping rows where the daily prices are NA we lose 0% rows "
=======
   "id": "listed-salad",
   "metadata": {},
   "source": [
    "### Load in the numerai targets"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix_nas(df, col_suffix='1d', id_cols=['date', 'bloomberg_ticker']):\n",
    "    \n",
    "    df_ids = df[[col for col in df.columns \\\n",
    "                 if col.endswith(col_suffix) \\\n",
    "                 or col in id_cols]\\\n",
    "               ].dropna()[id_cols].isin(df[id_cols])\n",
    "    \n",
    "    df = df[df[id_cols].isin(df_ids[id_cols])]\n",
    "    return df"
=======
   "execution_count": 21,
   "id": "african-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.56 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4294278</th>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2021-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294279</th>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2021-03-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bloomberg_ticker  friday_date   data_type  target       date\n",
       "4294278          ZYXI US     20210319  validation    0.75 2021-03-19\n",
       "4294279           ZZZ CN     20210319  validation    0.50 2021-03-19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv' # old\n",
    "targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val_bbg.csv'\n",
    "targets = pd.read_csv(targets_address)\\\n",
    "    .assign(date = lambda df: pd.to_datetime(df['friday_date'], format='%Y%m%d'))\n",
    "targets.tail(2)"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 3 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DROP_1D_NAS = False\n",
    "if DROP_1D_NAS:\n",
    "    df_yahoo = drop_suffix_nas(df_yahoo, col_suffix='1d')\n",
    "\n",
    "DROP_1H_NAS = False\n",
    "if DROP_1H_NAS:\n",
    "    df_yahoo = drop_suffix_nas(df_yahoo, col_suffix='1h')"
=======
   "execution_count": 22,
   "id": "comparative-field",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    2148478\n",
       "0.25     858391\n",
       "0.75     857948\n",
       "1.00     214798\n",
       "0.00     214665\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['target'].value_counts()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "# Create Features\n",
    "### Create naive features"
=======
   "id": "indirect-exemption",
   "metadata": {},
   "source": [
    "### Merge targets into ddf_yahoo\n",
    "- From an inner join on `['date', 'bloomberg_ticker']` we lose about 85% of rows. <br>\n",
    "- If we drop rows with NAs we have 0 rows left no matter what. <br>\n",
    "- The best bet seems to be an outer join without dropping NA rows."
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 23,
   "id": "headed-credits",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 134 ms, sys: 4.7 ms, total: 138 ms\n",
      "Wall time: 138 ms\n"
=======
      "Wall time: 1.83 s\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['1 HK',\n",
       " '000100 KS',\n",
       " '2 HK',\n",
       " '000210 KS',\n",
       " '000240 KS',\n",
       " '000270 KS',\n",
       " '3 HK',\n",
       " '4 HK',\n",
       " '6 HK',\n",
       " '000660 KS']"
      ]
     },
     "execution_count": 24,
=======
       "(153, 17616897)"
      ]
     },
     "execution_count": 23,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "TICKERS = df_yahoo['bloomberg_ticker'].unique().tolist()\n",
    "TICKERS[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_naive_features_single_symbol(df,\\\n",
    "                                        symbol='',\\\n",
    "                                        symbol_sep='',\\\n",
    "                                        open_col='open_1d',\\\n",
    "                                        high_col='high_1d',\\\n",
    "                                        low_col='low_1d',\\\n",
    "                                        close_col='adj_close_1d',\\\n",
    "                                        volume_col='volume_1d',\\\n",
    "                                        new_col_suffix='_1d',\\\n",
    "                                        copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    __________ \n",
    "    \n",
    "    df: Pandas-like / dask dataframe\n",
    "        For the stacked yfinance data used for numerai, the syntax is <groupby('bloomberg_ticker').apply(func)>\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "\n",
    "    df['move' + new_col_suffix] = df[close_col] - df[open_col]\n",
    "    df['move_pct' + new_col_suffix] = df['move' + new_col_suffix] / df[open_col]\n",
    "    df['move_pct_change' + new_col_suffix] = df['move' + new_col_suffix].pct_change()\n",
    "    df['open_minus_prev_close' + new_col_suffix] = df[open_col] - df[close_col].shift()\n",
    "    df['prev_close_pct_chg' + new_col_suffix] = df['move' + new_col_suffix] / df[close_col].shift()\n",
    "\n",
    "    df['range' + new_col_suffix] = df[high_col] - df[low_col]\n",
    "    df['range_pct_change' + new_col_suffix] = df['range' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['high_move' + new_col_suffix] = df[high_col] - df[open_col]\n",
    "    df['high_move_pct' + new_col_suffix] = df['high_move' + new_col_suffix] / df[open_col]\n",
    "    df['high_move_pct_change' + new_col_suffix] = df['high_move' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['low_move' + new_col_suffix] = df[low_col] - df[open_col]\n",
    "    df['low_move_pct' + new_col_suffix] = df['low_move' + new_col_suffix] / df[open_col]\n",
    "    df['low_move_pct_change' + new_col_suffix] = df['low_move' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['volume_diff' + new_col_suffix] = df[volume_col] - df[volume_col].shift()\n",
    "    df['volume_pct_change' + new_col_suffix] = df[volume_col].pct_change()\n",
    "\n",
    "    df['close_minus_low' + new_col_suffix] = df[close_col] - df[low_col]\n",
    "    df['high_minus_close' + new_col_suffix] = df[high_col] - df[close_col]\n",
    "\n",
    "    df['prev_close_minus_low_minus' + new_col_suffix] = df[close_col].shift() - df[low_col]\n",
    "    df['high_minus_prev_close' + new_col_suffix] = df[high_col] - df[close_col].shift()\n",
    "\n",
    "    return df"
=======
    "ddf_yahoo.shape[1], ddf_yahoo.shape[0].compute()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 24,
   "id": "asian-yorkshire",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 1min 7s, sys: 2.85 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
=======
      "Wall time: 2.12 s\n"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
=======
       "      <th>date</th>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
<<<<<<< HEAD
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>high_move_pct_change_1d</th>\n",
       "      <th>low_move_1d</th>\n",
       "      <th>low_move_pct_1d</th>\n",
       "      <th>low_move_pct_change_1d</th>\n",
       "      <th>volume_diff_1d</th>\n",
       "      <th>volume_pct_change_1d</th>\n",
       "      <th>close_minus_low_1d</th>\n",
       "      <th>high_minus_close_1d</th>\n",
       "      <th>prev_close_minus_low_minus_1d</th>\n",
       "      <th>high_minus_prev_close_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
=======
       "      <th>...</th>\n",
       "      <th>volume_1h_18</th>\n",
       "      <th>volume_1h_19</th>\n",
       "      <th>volume_1h_20</th>\n",
       "      <th>volume_1h_21</th>\n",
       "      <th>volume_1h_22</th>\n",
       "      <th>volume_1h_23</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673917</td>\n",
       "      <td>-0.390001</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>1.085001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.390001</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430890</td>\n",
       "      <td>-0.084999</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.782054</td>\n",
       "      <td>-97900.0</td>\n",
       "      <td>-0.705331</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084999</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  high_move_pct_change_1d  low_move_1d  \\\n",
       "date                        ...                                         \n",
       "2021-03-12             NaN  ...                 0.000000    -0.590000   \n",
       "2021-03-19             NaN  ...                 1.673917    -0.390001   \n",
       "2021-03-19             NaN  ...                 0.000000    -0.390001   \n",
       "2021-03-26             NaN  ...                -0.430890    -0.084999   \n",
       "2021-03-26             NaN  ...                 0.000000    -0.084999   \n",
       "\n",
       "            low_move_pct_1d  low_move_pct_change_1d  volume_diff_1d  \\\n",
       "date                                                                  \n",
       "2021-03-12        -0.019287                0.000000             0.0   \n",
       "2021-03-19        -0.012472               -0.338981         15100.0   \n",
       "2021-03-19        -0.012472                0.000000             0.0   \n",
       "2021-03-26        -0.002681               -0.782054        -97900.0   \n",
       "2021-03-26        -0.002681                0.000000             0.0   \n",
       "\n",
       "            volume_pct_change_1d  close_minus_low_1d  high_minus_close_1d  \\\n",
       "date                                                                        \n",
       "2021-03-12              0.000000            0.799999             0.020000   \n",
       "2021-03-19              0.122070            0.850000             0.155001   \n",
       "2021-03-19              0.000000            0.850000             0.155001   \n",
       "2021-03-26             -0.705331            0.435001             0.000000   \n",
       "2021-03-26              0.000000            0.435001             0.000000   \n",
       "\n",
       "            prev_close_minus_low_minus_1d  high_minus_prev_close_1d  \n",
       "date                                                                 \n",
       "2021-03-12                       0.799999                  0.020000  \n",
       "2021-03-19                      -0.080000                  1.085001  \n",
       "2021-03-19                       0.850000                  0.155001  \n",
       "2021-03-26                       0.105000                  0.330002  \n",
       "2021-03-26                       0.435001                  0.000000  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = df_yahoo.groupby('bloomberg_ticker', group_keys=False).apply(create_naive_features_single_symbol)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create my own rule based targets as a feature\n",
    "These are things that I would be looking for before I make a trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateTargets():\n",
    "\n",
    "    def __init__(self, df, copy = True):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        __________\n",
    "\n",
    "        df : pandas df\n",
    "        copy : Boolean whether to make a copy of the df before applying transformations\n",
    "        \n",
    "        Note: to compute the target based on pct, pass the pct column names into the individual functions\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = df\n",
    "        self.copy = copy\n",
    "\n",
    "        if self.copy: self.df = self.df.copy()\n",
    "\n",
    "    def create_targets_HL5(self,\\\n",
    "                           strong_buy,\\\n",
    "                           med_buy,\\\n",
    "                           med_sell,\\\n",
    "                           strong_sell,\\\n",
    "                           threshold,\\\n",
    "                           stop,\\\n",
    "                           move_col = 'move_pct',\\\n",
    "                           lm_col = 'low_move_pct',\\\n",
    "                           hm_col = 'high_move_pct',\\\n",
    "                           target_suffix = 'target_HL5'):\n",
    "\n",
    "\n",
    "        # hm stands for high move, lm stands for low move\n",
    "        # Strong Buy\n",
    "        self.df.loc[(self.df[hm_col] >= strong_buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop),\\\n",
    "                            target_suffix] = 4\n",
    "\n",
    "        # Strong Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*strong_sell) &\\\n",
    "                    (self.df[hm_col] <= stop) &\\\n",
    "                    (self.df[target_suffix] != 4),\\\n",
    "                    target_suffix] = 0\n",
    "\n",
    "        # Medium Buy\n",
    "        self.df.loc[(self.df[hm_col] >= med_buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop) &\\\n",
    "                            (self.df[target_suffix] != 4) &\\\n",
    "                            (self.df[target_suffix] != 0),\\\n",
    "                            target_suffix] = 3\n",
    "\n",
    "        # Medium Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*med_sell) &\\\n",
    "                            (self.df[hm_col] <= stop) &\\\n",
    "                            (self.df[target_suffix] != 4) &\\\n",
    "                            (self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 3),\\\n",
    "                            target_suffix] = 1\n",
    "\n",
    "        # No Trade\n",
    "        self.df.loc[(self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 1) &\\\n",
    "                            (self.df[target_suffix] != 3) &\\\n",
    "                            (self.df[target_suffix] != 4),\\\n",
    "                            target_suffix] = 2\n",
    "\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def create_targets_HL3(self,\\\n",
    "                           buy,\\\n",
    "                           sell,\\\n",
    "                           threshold,\\\n",
    "                           stop,\\\n",
    "                           move_col = 'move_pct',\\\n",
    "                           lm_col = 'low_move_pct',\\\n",
    "                           hm_col = 'high_move_pct',\\\n",
    "                           target_suffix = 'target_HL3'):\n",
    "\n",
    "\n",
    "        # hm stands for high move, lm stands for low move\n",
    "        # Buy\n",
    "        self.df.loc[(self.df[hm_col] >= buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop),\\\n",
    "                            target_suffix] = 2\n",
    "\n",
    "        # Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*sell) &\\\n",
    "                            (self.df[hm_col] <= stop) &\\\n",
    "                            (self.df[target_suffix] != 2),\\\n",
    "                            target_suffix] = 0\n",
    "\n",
    "        # No Trade\n",
    "        self.df.loc[(self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 2),\\\n",
    "                            target_suffix] = 1\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 378 ms, sys: 288 ms, total: 666 ms\n",
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = CreateTargets(df_yahoo).create_targets_HL3(buy=0.03,\\\n",
    "                                                      sell=0.03,\\\n",
    "                                                      threshold=0.25,\\\n",
    "                                                      stop=.01,\\\n",
    "                                                      move_col = 'move_pct_1d',\\\n",
    "                                                      lm_col = 'low_move_pct_1d',\\\n",
    "                                                      hm_col = 'high_move_pct_1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2224340\n",
       "0.0     213419\n",
       "2.0     195920\n",
       "Name: target_HL3, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0    0.844575\n",
       "0.0    0.081035\n",
       "2.0    0.074390\n",
       "Name: target_HL3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_yahoo['target_HL3'].value_counts()), display(df_yahoo['target_HL3'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 460 ms, sys: 285 ms, total: 745 ms\n",
      "Wall time: 746 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>low_move_pct_1d</th>\n",
       "      <th>low_move_pct_change_1d</th>\n",
       "      <th>volume_diff_1d</th>\n",
       "      <th>volume_pct_change_1d</th>\n",
       "      <th>close_minus_low_1d</th>\n",
       "      <th>high_minus_close_1d</th>\n",
       "      <th>prev_close_minus_low_minus_1d</th>\n",
       "      <th>high_minus_prev_close_1d</th>\n",
       "      <th>target_HL3</th>\n",
       "      <th>target_HL5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
=======
       "      <th>180084</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>ZURN.SW</td>\n",
       "      <td>394.899994</td>\n",
       "      <td>394.899994</td>\n",
       "      <td>396.899994</td>\n",
       "      <td>392.700012</td>\n",
       "      <td>394.299988</td>\n",
       "      <td>1122367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZURN SW</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180085</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>15.650000</td>\n",
       "      <td>547200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26440.0</td>\n",
       "      <td>125466.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180086</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>15.650000</td>\n",
       "      <td>547200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26440.0</td>\n",
       "      <td>125466.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180087</th>\n",
       "      <td>2021-03-19</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
<<<<<<< HEAD
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>1.085001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
=======
       "      <td>...</td>\n",
       "      <td>12237.0</td>\n",
       "      <td>25319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180088</th>\n",
       "      <td>2021-03-19</td>\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
<<<<<<< HEAD
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.782054</td>\n",
       "      <td>-97900.0</td>\n",
       "      <td>-0.705331</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.330002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  low_move_pct_1d  low_move_pct_change_1d  \\\n",
       "date                        ...                                            \n",
       "2021-03-12             NaN  ...        -0.019287                0.000000   \n",
       "2021-03-19             NaN  ...        -0.012472               -0.338981   \n",
       "2021-03-19             NaN  ...        -0.012472                0.000000   \n",
       "2021-03-26             NaN  ...        -0.002681               -0.782054   \n",
       "2021-03-26             NaN  ...        -0.002681                0.000000   \n",
       "\n",
       "            volume_diff_1d  volume_pct_change_1d  close_minus_low_1d  \\\n",
       "date                                                                   \n",
       "2021-03-12             0.0              0.000000            0.799999   \n",
       "2021-03-19         15100.0              0.122070            0.850000   \n",
       "2021-03-19             0.0              0.000000            0.850000   \n",
       "2021-03-26        -97900.0             -0.705331            0.435001   \n",
       "2021-03-26             0.0              0.000000            0.435001   \n",
       "\n",
       "            high_minus_close_1d  prev_close_minus_low_minus_1d  \\\n",
       "date                                                             \n",
       "2021-03-12             0.020000                       0.799999   \n",
       "2021-03-19             0.155001                      -0.080000   \n",
       "2021-03-19             0.155001                       0.850000   \n",
       "2021-03-26             0.000000                       0.105000   \n",
       "2021-03-26             0.000000                       0.435001   \n",
       "\n",
       "            high_minus_prev_close_1d  target_HL3  target_HL5  \n",
       "date                                                          \n",
       "2021-03-12                  0.020000         1.0         1.0  \n",
       "2021-03-19                  1.085001         1.0         3.0  \n",
       "2021-03-19                  0.155001         1.0         3.0  \n",
       "2021-03-26                  0.330002         1.0         2.0  \n",
       "2021-03-26                  0.000000         1.0         2.0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 30,
=======
       "      <td>...</td>\n",
       "      <td>12237.0</td>\n",
       "      <td>25319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date yahoo_ticker  adj_close_1d    close_1d     high_1d  \\\n",
       "180084 2021-03-19      ZURN.SW    394.899994  394.899994  396.899994   \n",
       "180085 2021-03-19         ZYXI     16.100000   16.100000   16.150000   \n",
       "180086 2021-03-19         ZYXI     16.100000   16.100000   16.150000   \n",
       "180087 2021-03-19       ZZZ.TO     31.730000   31.730000   31.885000   \n",
       "180088 2021-03-19       ZZZ.TO     31.730000   31.730000   31.885000   \n",
       "\n",
       "            low_1d     open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "180084  392.700012  394.299988  1122367.0             NaN             NaN   \n",
       "180085   15.320000   15.650000   547200.0             NaN             NaN   \n",
       "180086   15.320000   15.650000   547200.0             NaN             NaN   \n",
       "180087   30.879999   31.270000   138800.0             NaN             NaN   \n",
       "180088   30.879999   31.270000   138800.0             NaN             NaN   \n",
       "\n",
       "        ...  volume_1h_18  volume_1h_19  volume_1h_20  volume_1h_21  \\\n",
       "180084  ...           NaN           NaN           NaN           NaN   \n",
       "180085  ...       26440.0      125466.0           NaN           NaN   \n",
       "180086  ...       26440.0      125466.0           NaN           NaN   \n",
       "180087  ...       12237.0       25319.0           NaN           NaN   \n",
       "180088  ...       12237.0       25319.0           NaN           NaN   \n",
       "\n",
       "        volume_1h_22  volume_1h_23  bloomberg_ticker  friday_date   data_type  \\\n",
       "180084           NaN           NaN           ZURN SW     20210319  validation   \n",
       "180085           NaN           NaN           ZYXI US     20210319  validation   \n",
       "180086           NaN           NaN           ZYXI US     20210319  validation   \n",
       "180087           NaN           NaN            ZZZ CN     20210319  validation   \n",
       "180088           NaN           NaN            ZZZ CN     20210319  validation   \n",
       "\n",
       "        target  \n",
       "180084    0.50  \n",
       "180085    0.75  \n",
       "180086    0.75  \n",
       "180087    0.50  \n",
       "180088    0.50  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 24,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "df_yahoo = CreateTargets(df_yahoo).create_targets_HL5(strong_buy=0.035,\\\n",
    "                                                      med_buy=0.015,\\\n",
    "                                                      med_sell=0.015,\\\n",
    "                                                      strong_sell=0.035,\\\n",
    "                                                      threshold=0.25,\\\n",
    "                                                      stop=.025,\\\n",
    "                                                      move_col = 'move_pct_1d',\\\n",
    "                                                      lm_col = 'low_move_pct_1d',\\\n",
    "                                                      hm_col = 'high_move_pct_1d')\n",
    "df_yahoo.tail()"
=======
    "ddf_yahoo = dd.merge(ddf_yahoo, targets, on=['date', 'bloomberg_ticker'], how='inner')\n",
    "ddf_yahoo.tail()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 27,
   "id": "remarkable-queensland",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "2.0    1069661\n",
       "3.0     585406\n",
       "1.0     585000\n",
       "0.0     201187\n",
       "4.0     192425\n",
       "Name: target_HL5, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.0    0.406147\n",
       "3.0    0.222277\n",
       "1.0    0.222123\n",
       "0.0    0.076390\n",
       "4.0    0.073063\n",
       "Name: target_HL5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 31,
=======
       "(2623095, 156)"
      ]
     },
     "execution_count": 27,
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "display(df_yahoo['target_HL5'].value_counts()), display(df_yahoo['target_HL5'].value_counts(normalize=True))"
=======
    "ddf_yahoo.shape[0].compute(), ddf_yahoo.shape[1]"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Create some more features before applying preprocessing"
=======
   "id": "sorted-halifax",
   "metadata": {},
   "source": [
    "### First iteration - drop rows where the daily prices are NA"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagging_features(df, lagging_map, groupby_cols=None, new_col_prefix='prev', copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    \n",
    "    df : pandas df\n",
    "    groupby_cols : str or list of cols to groupby before creating lagging transformation cols\n",
    "    lagging_map : dict with keys as colnames and values as a list of periods for computing lagging features\n",
    "    periods : periods to look back\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "\n",
    "    unique_lagging_values = list(sorted({k for v in lagging_map.values() for k in v}))\n",
    "    \n",
    "    if groupby_cols is None or len(groupby_cols) == 0:\n",
    "        for period in unique_lagging_values:\n",
    "            new_col_prefix_tmp = new_col_prefix + str(period) + '_'\n",
    "            cols_to_lag = [k for k,v in lagging_map.items() if period in v]\n",
    "            df[[new_col_prefix_tmp + c for c in cols_to_lag]] = df[cols_to_lag].transform(lambda s: s.shift(periods=period))\n",
    "    \n",
    "    else:\n",
    "        for period in unique_lagging_values:\n",
    "            new_col_prefix_tmp = new_col_prefix + str(period) + '_'\n",
    "            cols_to_lag = [k for k,v in lagging_map.items() if period in v]\n",
    "            \n",
    "            df[[new_col_prefix_tmp + c for c in cols_to_lag]] = df.groupby(groupby_cols)[cols_to_lag]\\\n",
    "                                                                  .transform(lambda s: s.shift(periods=period))\n",
=======
   "execution_count": 53,
   "id": "specified-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_yahoo_reduced = df_yahoo[df_yahoo.index.isin(df_yahoo[[i for i in df_yahoo.columns if i.endswith('d')]].dropna().index)]\n",
    "# print(df_yahoo_reduced.shape)\n",
    "\n",
    "# df_yahoo_reduced.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "mineral-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix_nas(df, col_suffix='1d', id_cols=['date', 'bloomberg_ticker']):\n",
    "    \n",
    "    df_ids = df[[col for col in df.columns \\\n",
    "                 if col.endswith(col_suffix) \\\n",
    "                 or col in id_cols]\\\n",
    "               ].dropna()[id_cols].isin(df[id_cols])\n",
    "    \n",
    "    df = df[df[id_cols].isin(df_ids[id_cols])]\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': [1, 2, 3, 4, 5],\n",
       " 'target_HL5': [1, 2, 3, 4, 5],\n",
       " 'volume_1d': [1, 2, 3, 4, 5],\n",
       " 'adj_close_1d': [1, 2, 3, 4, 5],\n",
       " 'move_1d': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAGGING_MAP = {'target': [1, 2, 3, 4, 5],\\\n",
    "               'target_HL5': [1, 2, 3, 4, 5],\\\n",
    "               'volume_1d': [1, 2, 3, 4, 5],\\\n",
    "               'adj_close_1d' : [1, 2, 3, 4, 5],\\\n",
    "               'move_1d':[1,2,3,4,5]}\n",
    "LAGGING_MAP"
=======
   "execution_count": 108,
   "id": "grave-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_yahoo = ddf_yahoo.map_partitions(drop_suffix_nas)"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 4.17 s, total: 46.1 s\n",
      "Wall time: 46.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>prev4_target</th>\n",
       "      <th>prev4_target_HL5</th>\n",
       "      <th>prev4_volume_1d</th>\n",
       "      <th>prev4_adj_close_1d</th>\n",
       "      <th>prev4_move_1d</th>\n",
       "      <th>prev5_target</th>\n",
       "      <th>prev5_target_HL5</th>\n",
       "      <th>prev5_volume_1d</th>\n",
       "      <th>prev5_adj_close_1d</th>\n",
       "      <th>prev5_move_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  prev4_target  prev4_target_HL5  \\\n",
       "date                        ...                                   \n",
       "2021-03-12             NaN  ...          0.75               3.0   \n",
       "2021-03-19             NaN  ...          0.50               1.0   \n",
       "2021-03-19             NaN  ...          0.50               1.0   \n",
       "2021-03-26             NaN  ...          0.75               1.0   \n",
       "2021-03-26             NaN  ...          0.75               1.0   \n",
       "\n",
       "            prev4_volume_1d  prev4_adj_close_1d  prev4_move_1d  prev5_target  \\\n",
       "date                                                                           \n",
       "2021-03-12         106100.0           26.930000       0.600000          0.75   \n",
       "2021-03-19         340600.0           30.549999      -0.380001          0.75   \n",
       "2021-03-19         340600.0           30.549999      -0.380001          0.50   \n",
       "2021-03-26         123700.0           30.799999       0.209999          0.50   \n",
       "2021-03-26         123700.0           30.799999       0.209999          0.75   \n",
       "\n",
       "            prev5_target_HL5  prev5_volume_1d  prev5_adj_close_1d  \\\n",
       "date                                                                \n",
       "2021-03-12               3.0         106100.0           26.930000   \n",
       "2021-03-19               3.0         106100.0           26.930000   \n",
       "2021-03-19               1.0         340600.0           30.549999   \n",
       "2021-03-26               1.0         340600.0           30.549999   \n",
       "2021-03-26               1.0         123700.0           30.799999   \n",
       "\n",
       "            prev5_move_1d  \n",
       "date                       \n",
       "2021-03-12       0.600000  \n",
       "2021-03-19       0.600000  \n",
       "2021-03-19      -0.380001  \n",
       "2021-03-26      -0.380001  \n",
       "2021-03-26       0.209999  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = create_lagging_features(df_yahoo, groupby_cols='bloomberg_ticker', lagging_map=LAGGING_MAP)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rolling features"
=======
   "execution_count": null,
   "id": "minus-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_yahoo.map_partitions(drop_suffix_nas).shape[0].compute(), ddf_yahoo.map_partitions(drop_suffix_nas).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-observation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-corpus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-harvard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-passenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-emperor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-protein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-highlight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-screen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-evaluation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-robin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-commerce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_BLOOMBERG_TICKERS_AS_INDEX = True\n",
    "if SET_BLOOMBERG_TICKERS_AS_INDEX:\n",
    "    df_yahoo.reset_index(inplace=True)\n",
    "    df_yahoo.loc[:, 'bloomberg_ticker'] = df_yahoo['ticker'].map(dict(zip(ticker_map['yahoo'], ticker_map['bloomberg_ticker'])))\n",
    "    df_yahoo.set_index(['date', 'ticker'], inplace=True)\n",
    "df_yahoo.tail()"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": null,
   "id": "vulnerable-biography",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df,\\\n",
<<<<<<< HEAD
    "                            rolling_fn,\\\n",
    "                            rolling_params,\\\n",
    "                            ewm_fn,\\\n",
    "                            ewm_params,\\\n",
    "                            rolling_cols = 'all_numeric',\\\n",
    "                            ewm_cols='all_numeric',\\\n",
    "                            join_method='outer',\\\n",
    "                            groupby_cols=None,\\\n",
    "                            create_diff_cols=True,\n",
    "                            copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : pandas df\n",
    "    \n",
    "    rolling_fn : str called from df.rolling().rolling_fn (e.g. df.rolling.mean() is called with getattr)\n",
    "    rolling_params : dict params passed to df.rolling()\n",
    "    \n",
    "    ewm_fn : str called from df.ewm().ewm_fn (e.g. df.ewm.mean() is called with getattr)\n",
    "    ewm_params : dict params passed to df.ewm()\n",
    "    \n",
    "    rolling_cols : cols to apply rolling_fn\n",
    "    ewm_cols : cols to apply ewm_fn\n",
    "    \n",
    "    join_method : str 'inner', 'outer', 'left', or 'right' - how to join the dfs\n",
    "    groupby_cols : list or str cols to group by before applying rolling transformations\n",
    "        example: pass groupby_cols to the stacked ticker numerai dataset, but not a wide df \n",
    "    \n",
=======
    "                            rolling_params,\\\n",
    "                            rolling_fn,\\\n",
    "                            ewm_params,\\\n",
    "                            ewm_fn,\\\n",
    "                            rolling_cols = 'all_numeric',\\\n",
    "                            ewm_cols = 'all_numeric',\\\n",
    "                            join_method='outer',\\\n",
    "                            groupby_cols = None,\\\n",
    "                            copy=True):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    __________\n",
    "    groupby_cols : list or str cols to group by before applying rolling transformations\n",
    "        example: pass groupby_cols to the stacked ticker numerai dataset, but not a wide df \n",
    "    rolling_cols : cols to apply rolling_fn to\n",
    "    ewm_cols : cols to apply ewm_fn to\n",
    "    rolling_params : dict params passed to df.rolling()\n",
    "    rolling_fn : str called from df.rolling().rolling_fn (e.g. df.rolling.mean() is called with getattr)\n",
    "    ewm_params : dict params passed to df.ewm()\n",
    "    ewm_fn : str called from df.ewm().ewm_fn (e.g. df.ewm.mean() is called with getattr)\n",
    "    join_method : str 'inner', 'outer', 'left', or 'right' - how to join the dfs\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "    copy : bool whether or not to make a copy of the df\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "    \n",
<<<<<<< HEAD
    "    if isinstance(rolling_cols, str) and rolling_cols.lower() == 'all_numeric':\n",
    "        rolling_cols = list(df.select_dtypes(include=np.number).columns)\n",
    "    \n",
    "    if isinstance(rolling_cols, str) and ewm_cols.lower() == 'all_numeric':\n",
=======
    "    if rolling_cols.lower() == 'all_numeric':\n",
    "        rolling_cols = list(df.select_dtypes(include=np.number).columns)\n",
    "    if ewm_cols.lower() == 'all_numeric':\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "        ewm_cols = list(df.select_dtypes(include=np.number).columns)\n",
    "    \n",
    "    lag_dfs_lst = []\n",
    "    \n",
<<<<<<< HEAD
    "    if groupby_cols is None or len(groupby_cols) == 0:\n",
    "        \n",
=======
    "    if groupby_cols is None:\n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "        # rolling\n",
    "        lag_dfs_lst.append(getattr(df[rolling_cols].rolling(**rolling_params), rolling_fn)().add_suffix('_rolling_' + rolling_fn))\n",
    "        \n",
    "        # ewm\n",
    "        lag_dfs_lst.append(getattr(df[ewm_cols].ewm(**ewm_params), ewm_fn)().add_suffix('_ewm_' + ewm_fn))\n",
<<<<<<< HEAD
=======
    "    \n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "    else:\n",
    "        \n",
    "        if isinstance(groupby_cols, list):\n",
    "            assert(len(groupby_cols) == len(set(groupby_cols))), 'There are duplicates in groupby_cols!'\n",
    "            rolling_cols_to_select = [i for i in list(set(groupby_cols + rolling_cols)) if i in df.columns] # could be index name\n",
    "            ewm_cols_to_select = [i for i in list(set(groupby_cols + ewm_cols)) if i in df.columns] # could be index name\n",
    "        elif isinstance(groupby_cols, str):\n",
    "            rolling_cols_to_select = [i for i in list(set([groupby_cols] + rolling_cols)) if i in df.columns]\n",
    "            ewm_cols_to_select = [i for i in list(set([groupby_cols] + ewm_cols)) if i in df.columns]\n",
    "        else:\n",
    "            raise('Input param groupby_cols is not a list, string, or None!')\n",
    "        \n",
    "        # rolling\n",
    "        lag_dfs_lst.append(\n",
    "            df[rolling_cols_to_select].\\\n",
    "            groupby(groupby_cols).\\\n",
    "            apply(lambda x: getattr(x.rolling(**rolling_params), rolling_fn)()).\\\n",
    "            add_suffix('_rolling_' + rolling_fn)\\\n",
    "        )\n",
    "        \n",
    "        # ewm\n",
    "        lag_dfs_lst.append(\n",
    "            df[ewm_cols_to_select].\\\n",
    "            groupby(groupby_cols).\\\n",
    "            apply(lambda x: getattr(x.ewm(**ewm_params), ewm_fn)()).\\\n",
    "            add_suffix('_ewm_' + ewm_fn)\\\n",
    "        )\n",
    "\n",
    "    df_lag = reduce(lambda x, y: pd.merge(x, y, how=join_method, left_index=True, right_index=True), lag_dfs_lst)    \n",
<<<<<<< HEAD
    "    del lag_dfs_lst\n",
    "    df = pd.merge(df, df_lag, how=join_method, left_index=True, right_index=True)\n",
    "    \n",
    "    del df_lag\n",
    "    \n",
    "    if create_diff_cols:\n",
    "        if groupby_cols is None or len(groupby_cols) == 0:\n",
    "            df = pd.concat([df, df[[i for i in df.columns if 'ewm' in i or 'rolling' in i]].diff().add_suffix('_diff')], axis=1)\n",
    "        else:\n",
    "            diff_cols = [i for i in df.columns if 'ewm' in i or 'rolling' in i]\n",
    "            df[[i + '_diff' for i in diff_cols]] = df.groupby(groupby_cols)[diff_cols].transform(lambda col: col.diff())\n",
=======
    "    \n",
    "    df = pd.merge(df, df_lag, how=join_method, left_index=True, right_index=True)\n",
    "    \n",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Below will use over 130gb of ram if running through jupyter notebook. This notebook will be converted to a py script, which is less memory greedy"
=======
   "execution_count": null,
   "id": "technical-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yahoo.shape"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
=======
   "id": "indonesian-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
    "df_yahoo = create_rolling_features(df_yahoo,\\\n",
    "                                   rolling_params={'window':30},\\\n",
    "                                   rolling_fn='mean',\\\n",
    "                                   ewm_params={'com':.5},\\\n",
    "                                   ewm_fn='mean',\\\n",
<<<<<<< HEAD
    "                                   rolling_cols = ['open_1d', 'high_1d', 'low_1d', 'adj_close_1d', 'volume_1d', 'prev1_target', 'prev1_target_HL5'],\\\n",
    "                                   ewm_cols = ['open_1d', 'high_1d', 'low_1d', 'adj_close_1d', 'volume_1d', 'prev1_target', 'prev1_target_HL5'],\\\n",
    "                                   join_method='outer',\\\n",
    "                                   groupby_cols = 'bloomberg_ticker',\\\n",
    "                                   create_diff_cols=True)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a good checkpoint to save the df"
=======
    "                                   rolling_cols = 'all_numeric',\\\n",
    "                                   ewm_cols = 'all_numeric',\\\n",
    "                                   join_method='outer',\\\n",
    "                                   groupby_cols = 'ticker')\n",
    "df_yahoo.tail(2)"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yahoo.reset_index(drop=True).to_feather(OUTPUT_PATH + 'df_numerai_' + str(datetime.datetime.today().date()) + '.feather')"
=======
   "execution_count": null,
   "id": "approximate-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yahoo.shape"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "historic-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['date'] = pd.to_datetime(targets['friday_date'], format='%Y%m%d')\n",
    "targets.set_index(['date', 'ticker'], inplace=True)\n",
    "targets.index.names = ['date', 'ticker']\n",
    "\n",
    "targets.tail(2)"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "executive-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(df_yahoo, targets, how='outer', left_index=True, right_index=True)\n",
    "df_full.drop('friday_date', axis=1, inplace=True)\n",
    "df_full.tail()"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "charitable-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "fresh-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_yahoo, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-ceremony",
   "metadata": {},
   "source": [
    "### There are a lot of missing targets. What do we do with them?\n",
    "- This becomes a semi-supervised learning problem since there is likely predictive information where there is no numerai target <br>\n",
    "- To fill them in, I'm going to take an educated guess and say that Numerai's targets are created based on profitable up moves in the market. <br>\n",
    "- The target they created is likely the following multi-class groups: **strong-short**, **short**, **no-trade**, **buy**, **strong-buy** - Let's find out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-torture",
   "metadata": {},
   "source": [
    "#### First get the tickers available in the target df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "assumed-satellite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4294278</th>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294279</th>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210319</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bloomberg_ticker  friday_date   data_type  target\n",
       "4294278          ZYXI US     20210319  validation    0.75\n",
       "4294279           ZZZ CN     20210319  validation    0.50"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv' # old\n",
    "targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val_bbg.csv'\n",
    "targets = pd.read_csv(targets_address)\n",
    "\n",
    "targets.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "residential-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3931"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_with_target = list(set(\\\n",
    "                               list(set(ticker_map['bloomberg_ticker'].unique().tolist()).\\\n",
    "                                    intersection(targets['ticker'].unique().tolist())) + \\\n",
    "                               list(set(ticker_map['yahoo'].unique().tolist()).\\\n",
    "                                    intersection(targets['ticker'].unique().tolist()))\\\n",
    "                              ))\n",
    "len(tickers_with_target)"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "vocal-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full['target'].notnull()]"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "id": "hindu-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.dropna()"
   ]
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "isolated-painting",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a lot of missing targets. What do we do with them?\n",
    "- This becomes a semi-supervised learning problem since there is likely predictive information where there is no numerai target <br>\n",
    "- To fill them in, I'm going to take an educated guess and say that Numerai's targets are created based on profitable up moves in the market. <br>\n",
    "- The target they created is likely the following multi-class groups: **strong-short**, **short**, **no-trade**, **buy**, **strong-buy** - Let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5337, 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_with_target = df_yahoo.loc[df_yahoo['target'].notnull(), 'bloomberg_ticker'].unique().tolist()\n",
    "tickers_without_target = df_yahoo.loc[df_yahoo['target'].isnull(), 'bloomberg_ticker'].unique().tolist()\n",
    "len(tickers_with_target), len(tickers_without_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-assault",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "interested-disposal",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "reliable-delicious",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "northern-doubt",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "unlike-penny",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "documented-amendment",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "swiss-appearance",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "critical-solution",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "behind-magic",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "standard-roller",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "UOFVjPU0yu7A",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "UOFVjPU0yu7A"
   },
   "outputs": [],
   "source": [
    "ticker_groups = full_data.groupby('ticker')\n",
    "\n",
    "#create lagged features, lag 0 is that day's value, lag 1 is yesterday's value, etc\n",
    "num_days = 5\n",
    "for day in range(num_days+1):\n",
    "    full_data[f'RSI_quintile_lag_{day}'] = ticker_groups['RSI_quintile'].transform(lambda group: group.shift(day))\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "Es0O8RKKyu-a",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "Es0O8RKKyu-a"
   },
   "outputs": [],
   "source": [
    "# create difference of the lagged features (change in RSI quintile by day)\n",
    "for day in range(num_days):\n",
    "    full_data[f'RSI_diff_{day}'] = full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}']\n",
    "    full_data[f'RSI_abs_diff_{day}'] = np.abs(full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "xkrsTeFuyvBq",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "xkrsTeFuyvBq"
   },
   "outputs": [],
   "source": [
    "feature_names = [f'RSI_quintile_lag_{num}' for num in range(num_days)] + [f'RSI_diff_{num}' for num in range(num_days)] + [f'RSI_abs_diff_{num}' for num in range(num_days)]\n",
    "print(f'Features for training:\\n {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "KahFrrERyvE5",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "KahFrrERyvE5"
   },
   "outputs": [],
   "source": [
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "8dqoFqMzyvIG",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "8dqoFqMzyvIG"
   },
   "outputs": [],
   "source": [
    "# read in Signals targets\n",
    "numerai_targets = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv'\n",
    "targets = pd.read_csv(numerai_targets)\n",
    "targets['date'] = pd.to_datetime(targets['friday_date'], format='%Y%m%d')\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "m0XWeLvZyvLr",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "m0XWeLvZyvLr"
   },
   "outputs": [],
   "source": [
    "# the number of tickers per era has generally increased\n",
    "targets.groupby('date').apply(lambda x: len(x)).plot(kind='line', figsize=(10,4), title='Number of tickers per era')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "wqC4bJX2yvO8",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "wqC4bJX2yvO8"
   },
   "outputs": [],
   "source": [
    "# the target classes are imbalanced, but we can treat this like a regression problem\n",
    "targets.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "CVF1kpUkyvSe",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "CVF1kpUkyvSe"
   },
   "outputs": [],
   "source": [
    "# the imbalance is consistent across eras with a constant class ratio of: 5%, 20%, 50%, 20%, 5%\n",
    "pivot_target = targets.groupby(['date','target']).apply(lambda x: len(x)).reset_index(1).pivot(columns='target',values=0)\n",
    "pivot_target.iloc[::20].plot(kind='bar', stacked=True, figsize=(9,3), title='Number of tickers in each class per era')\n",
    "\n",
    "stacked_data = pivot_target.apply(lambda x: x/sum(x), axis=1)\n",
    "stacked_data.iloc[::20].plot(kind='bar', stacked=True, figsize=(9,3), title='Proportion of tickers in each class per era')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "A7nFiUa-yvXy",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "A7nFiUa-yvXy"
   },
   "outputs": [],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "dL1psmzPyvbs",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "dL1psmzPyvbs"
   },
   "outputs": [],
   "source": [
    "# merge our feature data with Numerai targets\n",
    "ML_data = pd.merge(full_data.reset_index(), targets, on=['date','ticker']).set_index('date')\n",
    "# print(f'Number of eras in data: {len(ML_data.index.unique())}')\n",
    "\n",
    "# for training and testing we want clean, complete data only\n",
    "ML_data.dropna(inplace=True)\n",
    "ML_data = ML_data[ML_data.index.weekday==4] # ensure we have only fridays\n",
    "ML_data = ML_data[ML_data.index.value_counts() > 200] # drop eras with under 200 observations per era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "UeymnV_nzT5d",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "UeymnV_nzT5d"
   },
   "outputs": [],
   "source": [
    "print(f'Number of eras in data: {len(ML_data.index.unique())}')\n",
    "ML_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "zcLutuwHzT8_",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "zcLutuwHzT8_"
   },
   "outputs": [],
   "source": [
    "train_data = ML_data[ML_data['data_type'] == 'train']\n",
    "test_data = ML_data[ML_data['data_type'] == 'validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "pWE4J6ihzUAR",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "pWE4J6ihzUAR"
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(train_data[feature_names], train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "JmssRtBKzUDS",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "JmssRtBKzUDS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.bar(feature_names, model.feature_importances_)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "snk6cOZTzUHN",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "snk6cOZTzUHN"
   },
   "outputs": [],
   "source": [
    "PREDICTION_NAME = 'prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "iwdod193zUKP",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "iwdod193zUKP"
   },
   "outputs": [],
   "source": [
    "train_data[PREDICTION_NAME] = model.predict(train_data[feature_names])\n",
    "test_data[PREDICTION_NAME] = model.predict(test_data[feature_names])\n",
    "\n",
    "#show prediction distribution, most should around the center\n",
    "test_data[PREDICTION_NAME].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "h5OK3cJvzUNw",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "h5OK3cJvzUNw"
   },
   "outputs": [],
   "source": [
    "def score(df):\n",
    "    '''Takes df and calculates spearm correlation from pre-defined cols'''\n",
    "    # method=\"first\" breaks ties based on order in array\n",
    "    return np.corrcoef(\n",
    "        df[TARGET_NAME],\n",
    "        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n",
    "    )[0,1]\n",
    "\n",
    "def run_analytics(era_scores):\n",
    "    print(f\"Mean Correlation: {era_scores.mean():.4f}\")\n",
    "    print(f\"Median Correlation: {era_scores.median():.4f}\")\n",
    "    print(f\"Standard Deviation: {era_scores.std():.4f}\")\n",
    "    print('\\n')\n",
    "    print(f\"Mean Pseudo-Sharpe: {era_scores.mean()/era_scores.std():.4f}\")\n",
    "    print(f\"Median Pseudo-Sharpe: {era_scores.median()/era_scores.std():.4f}\")\n",
    "    print('\\n')\n",
    "    print(f'Hit Rate (% positive eras): {era_scores.apply(lambda x: np.sign(x)).value_counts()[1]/len(era_scores):.2%}')\n",
    "\n",
    "    era_scores.rolling(10).mean().plot(kind='line', title='Rolling Per Era Correlation Mean', figsize=(15,4))\n",
    "    plt.axhline(y=0.0, color=\"r\", linestyle=\"--\"); plt.show()\n",
    "\n",
    "    era_scores.cumsum().plot(title='Cumulative Sum of Era Scores', figsize=(15,4))\n",
    "    plt.axhline(y=0.0, color=\"r\", linestyle=\"--\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "1_pLA3_PzURS",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "1_pLA3_PzURS"
   },
   "outputs": [],
   "source": [
    "# spearman scores by era\n",
    "train_era_scores = train_data.groupby(train_data.index).apply(score)\n",
    "test_era_scores = test_data.groupby(test_data.index).apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "JHPMlABQzUUd",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "JHPMlABQzUUd"
   },
   "outputs": [],
   "source": [
    "#train scores, in-sample and will be significantly overfit\n",
    "run_analytics(train_era_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "uFsUxckKzUYj",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "uFsUxckKzUYj"
   },
   "outputs": [],
   "source": [
    "#test scores, out of sample\n",
    "run_analytics(test_era_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "t30vuingzUbd",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "t30vuingzUbd"
   },
   "outputs": [],
   "source": [
    "# choose data as of most recent friday\n",
    "last_friday = datetime.now() + relativedelta(weekday=FR(-1))\n",
    "date_string = last_friday.strftime('%Y-%m-%d')\n",
    "\n",
    "live_data = full_data.loc[date_string].copy()\n",
    "live_data.dropna(subset=feature_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "WEhtlB4DzUfL",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "WEhtlB4DzUfL"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of live tickers to submit: {len(live_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "jPmPsAGYztjQ",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "jPmPsAGYztjQ"
   },
   "outputs": [],
   "source": [
    "live_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "R2er-yacztmB",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "R2er-yacztmB"
   },
   "outputs": [],
   "source": [
    "live_data[PREDICTION_NAME] = model.predict(live_data[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "ISCnCGQDztop",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "ISCnCGQDztop"
   },
   "outputs": [],
   "source": [
    "diagnostic_df = pd.concat([test_data, live_data])\n",
    "diagnostic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "R5pfv7VTztr9",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "R5pfv7VTztr9"
   },
   "outputs": [],
   "source": [
    "diagnostic_df['friday_date'] = diagnostic_df.friday_date.fillna(last_friday.strftime('%Y%m%d')).astype(int)\n",
    "diagnostic_df['data_type'] = diagnostic_df.data_type.fillna('live')\n",
    "diagnostic_df[['ticker','friday_date','data_type','prediction']].reset_index(drop=True).to_csv('example_signal_upload.csv', index=False)\n",
    "diagnostic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "bGWNHsMDztuq",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "bGWNHsMDztuq"
   },
   "outputs": [],
   "source": [
    "# format predictions to match Numerai submission format\n",
    "predictions = live_data[['ticker', PREDICTION_NAME]].copy()\n",
    "\n",
    "# choose account\n",
    "ACCOUNT_NAME = 'ENTER_ACCOUNT_NAME'\n",
    "\n",
    "# write predictions to csv\n",
    "live_data[['ticker', PREDICTION_NAME]].to_csv(f\"{ACCOUNT_NAME} {datetime.now().strftime('%Y%m%d')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "WBoZIk_xztxf",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "WBoZIk_xztxf"
   },
   "outputs": [],
   "source": [
    "def submit_model(account_name):\n",
    "    filename = f\"{account_name} {datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "    model_id = napi.get_models()[f'{account_name}']\n",
    "    submission = napi.upload_predictions(filename, model_id=model_id)\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "q7M_Y8bYzt07",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "q7M_Y8bYzt07"
   },
   "outputs": [],
   "source": [
    "submit_model(ACCOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "Pd23tVq_zt3_",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "Pd23tVq_zt3_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
   "metadata": {
    "id": "80DA0_H-zt7V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      df_yahoo:  4.4 GiB\n",
      "                       targets: 623.9 MiB\n",
      "                    ticker_map:  1.0 MiB\n",
      "              eligible_tickers: 338.2 KiB\n",
      "                 valid_tickers: 47.3 KiB\n",
      "                       TICKERS: 42.0 KiB\n",
      "                           _40:  9.1 KiB\n",
      "                           _34:  8.7 KiB\n",
      "                           _30:  7.8 KiB\n",
      "                           _26:  7.7 KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
=======
   "execution_count": null,
   "id": "80DA0_H-zt7V",
   "metadata": {
    "id": "80DA0_H-zt7V"
   },
   "outputs": [],
   "source": []
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "ep_UuQiVzt-X",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "ep_UuQiVzt-X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "Yn45a8_ozuBK",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "Yn45a8_ozuBK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "_fo8lf2BzuEe",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {
    "id": "_fo8lf2BzuEe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
<<<<<<< HEAD
=======
   "id": "discrete-corpus",
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def download_yfinance_data(tickers,\n",
      "                           intervals_to_download=['1d', '1h'],\n",
      "                           num_workers=1,\n",
      "                           join_method='outer',\n",
      "                           max_intraday_lookback_days=363,\n",
      "                           **yfinance_params):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    __________\n",
      "\n",
      "    See yfinance.download docs for a detailed description of yfinance parameters\n",
      "\n",
      "    tickers : string separated by space tickers to pass to yfinance.download (e.g. \"AAPL MSFT FB\")\n",
      "    intervals_to_download : list of intervals to download OHLCV data for each stock (e.g. ['1w', '1d', '1h'])\n",
      "    num_workers : number of threads used to download the data\n",
      "        so far only 1 thread is implemented\n",
      "    join_method : can be 'inner', 'left', 'right' or 'outer'\n",
      "        if 'outer' then all dates will be present\n",
      "        if 'left' then all dates from the left most table will be present\n",
      "        if 'right' then all dates from the left most table will be present\n",
      "        if 'inner' then all dates must match for each ticker\n",
      "    **yfinance_params : dict - passed to yfinance.dowload(yfinance_params)\n",
      "\n",
      "    NOTE: passing some intervals return unreliable stock data (e.g. '3mo' returns many NA data points when they should not be NA)\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    yfinance_params2 = yfinance_params.copy() # create a copy for min / hour pulls because the start date can only go back 60 days\n",
      "\n",
      "    if num_workers == 1:\n",
      "\n",
      "        list_of_dfs = []\n",
      "\n",
      "        for i in intervals_to_download:\n",
      "\n",
      "            yfinance_params['interval'] = i\n",
      "\n",
      "            if i.endswith('m') or i.endswith('h'): # min or hr\n",
      "\n",
      "                yfinance_params2['interval'] = i\n",
      "                yfinance_params2['start'] = str(datetime.datetime.today().date() - datetime.timedelta(days=max_intraday_lookback_days))\n",
      "\n",
      "\n",
      "                df_i = yfinance.download(tickers, **yfinance_params2).\\\n",
      "                        stack().\\\n",
      "                        add_suffix('_' + str(i)).\\\n",
      "                        reset_index(level=1).\\\n",
      "                        rename(columns={'level_1' : 'ticker'})\n",
      "\n",
      "                df_i = df_i.pivot_table(index=df_i.index.date, columns = ['ticker', df_i.index.hour]).stack(level=1)\n",
      "                df_i.columns = list(pd.Index([str(e[0]).lower() + '_' + str(e[1]).lower() for e in df_i.columns.tolist()]).str.replace(' ', '_'))\n",
      "\n",
      "            else:\n",
      "                df_i = yfinance.download(tickers, **yfinance_params).\\\n",
      "                        stack().\\\n",
      "                        add_suffix('_' + str(i))\n",
      "\n",
      "                df_i.columns = [col.replace(' ', '_').lower() for col in df_i.columns]\n",
      "\n",
      "            df_i.index.names = ['date', 'ticker']\n",
      "\n",
      "            list_of_dfs.append(df_i)\n",
      "\n",
      "\n",
      "        df_yahoo = reduce(lambda x, y: pd.merge(x, y, how=join_method, left_index=True, right_index=True), list_of_dfs)\n",
      "#         df_yahoo.reset_index(level=1, inplace=True)\n",
      "\n",
      "    else:\n",
      "        return 'multi-threading not implemented yet. Set num_workers to 1.'\n",
      "\n",
      "    return df_yahoo\n"
     ]
    }
   ],
   "source": [
    "import inspect as i\n",
    "import sys\n",
    "sys.stdout.write(i.getsource(download_yfinance_data))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "build_numerai_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.9.1"
>>>>>>> 607218e44551219d2aa08469d9fe08dc6e05db2a
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
